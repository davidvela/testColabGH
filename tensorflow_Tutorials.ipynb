{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_Tutorials.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "MhoQ0WE77laV",
        "jYysdyb-CaWM",
        "LteTUhcRrwka",
        "LWK8JpoovtgN",
        "403mugX_vrS-",
        "vI8y0Nfwo7iZ",
        "4mzXTYXobQT7",
        "DJQ0kaxovuF_"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/davidvela/testColabGH/blob/master/tensorflow_Tutorials.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "lHo_KGPfrkOi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorflow Tutorials - Intro"
      ]
    },
    {
      "metadata": {
        "id": "AQYbGjDxtsxf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "my noes: \n",
        "seems like tensorflow examples are getting more and more closed to keros... <br> \n",
        "the code seems more simple and with less lines. <br> \n",
        "the question is if it will affect performance and if keras has all the objects and all the customization from the old tensorflow libraries... (tf.layers ... )"
      ]
    },
    {
      "metadata": {
        "id": "MhoQ0WE77laV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "metadata": {
        "id": "-RUny0cBYnO3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ckMIh7O7s6D",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vasWnqRgy1H4",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jYysdyb-CaWM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST dataset\n",
        "Train your first neural network: basic classification\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "S5Uhzt6vVIB2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/basic_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/models/blob/master/samples/core/tutorials/keras/basic_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/samples/core/tutorials/keras/basic_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "FbVhjPpzn6BM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This guide uses [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow."
      ]
    },
    {
      "metadata": {
        "id": "DLdCchMdCaWQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This guide uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Fashion MNIST is intended as a drop-in replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset—often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc) in an identical format to the articles of clothing we'll use here.\n",
        "\n",
        "This guide uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code. \n",
        "\n",
        "We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow, just import and load the data:"
      ]
    },
    {
      "metadata": {
        "id": "dzLKpmZICaWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8550b9d7-a37c-4465-af68-f4e39833391c"
      },
      "cell_type": "code",
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7MqDQO0KCaWS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "#      0             1          2          3       4         5        6       7         8       9\n",
        "# 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Brm0b_KACaWX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Explore the data\n",
        "\n",
        "Let's explore the format of the dataset before training the model. The following shows there are 60,000 images in the training set, with each image represented as 28 x 28 pixels:"
      ]
    },
    {
      "metadata": {
        "id": "zW5k_xz1CaWX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train_images.shape) \n",
        "print(len(train_labels))\n",
        "print(train_labels)\n",
        "print(test_images.shape)\n",
        "print(len(test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ES6uQoLKCaWr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess the data\n",
        "\n",
        "The data must be preprocessed before training the network. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255:"
      ]
    },
    {
      "metadata": {
        "id": "m4VEw8Ud9Quh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.gca().grid(False)\n",
        "# scale values from 0 to 1. \n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ee638AlnCaWz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Display the first 25 images from the *training set* and display the class name below each image. Verify that the data is in the correct format and we're ready to build and train the network."
      ]
    },
    {
      "metadata": {
        "id": "oZTImqg_CaW1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid('off')\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "59veuiEZCaW4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "\n",
        "Building the neural network requires configuring the layers of the model, then compiling the model."
      ]
    },
    {
      "metadata": {
        "id": "9ODch-OFCaW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lhan11blCaW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train the model: \n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the model: \n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n",
        "#  This model reaches an accuracy of about 0.88 (or 88%) on the training data.\n",
        "\n",
        "# Testing\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# examples: \n",
        "print(predictions[0])\n",
        "print(np.argmax(predictions[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sd7Pgsu6CaXP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xsoS7CPDCaXH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make predictions\n",
        "\n",
        "With the model trained, we can use it to make predictions about some images."
      ]
    },
    {
      "metadata": {
        "id": "kgdvGD52CaXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's plot several images with their predictions. Correct prediction labels are green and incorrect prediction labels are red."
      ]
    },
    {
      "metadata": {
        "id": "YGBDAiziCaXR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot the first 25 test images, their predicted label, and the true label\n",
        "# Color correct predictions in green, incorrect predictions in red\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid('off')\n",
        "    plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
        "    predicted_label = np.argmax(predictions[i])\n",
        "    true_label = test_labels[i]\n",
        "    if predicted_label == true_label:\n",
        "      color = 'green'\n",
        "    else:\n",
        "      color = 'red'\n",
        "    plt.xlabel(\"{} ({})\".format(class_names[predicted_label], \n",
        "                                  class_names[true_label]),\n",
        "                                  color=color)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R32zteKHCaXT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, use the trained model to make a prediction about a single image. "
      ]
    },
    {
      "metadata": {
        "id": "yRJ7JU7JCaXT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Grab an image from the test dataset\n",
        "img = test_images[0]\n",
        "print(img.shape)\n",
        "# Add the image to a batch where it's the only member.\n",
        "img = (np.expand_dims(img,0))\n",
        "print(img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQ5wLTkcCaXY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now predict the image:"
      ]
    },
    {
      "metadata": {
        "id": "o_rzNSdrCaXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(img)\n",
        "print(predictions)\n",
        "prediction = predictions[0]\n",
        "np.argmax(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LteTUhcRrwka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The Boston Housing Prices dataset"
      ]
    },
    {
      "metadata": {
        "id": "EOH9n3I3ryDe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ... "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cg9j7BvCry87",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NbrmdxBjvW_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CMY8myeXvXCD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9FOgqpK7vXFF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LWK8JpoovtgN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Machine Translation with Attention\n",
        "   <table class=\"tfo-notebook-buttons\" align=\"left\"><td>\n",
        "      <a target=\"_blank\"  href=\"https://colab.sandbox.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb\">\n",
        "      <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "        <span>Run in Google Colab</span></a>  \n",
        "        </td><td>\n",
        "        <a target=\"_blank\"  href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /><span>View source on GitHub</span></a></td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "SQWL6xObvtgO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ... "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9Zxli-2vtgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# Import TensorFlow >= 1.9 and enable eager execution\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m8OWSnw3vtgS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nf-X51i-vtgV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkChf5oyvtga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4D7q3Pt6ZY_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "403mugX_vrS-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorflowHub  (TH)\n",
        "  https://www.tensorflow.org/hub/ <br>\n",
        "  modules: https://www.tensorflow.org/hub/modules/google/imagenet/inception_resnet_v2/classification/1\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "cajYirVJ0gcK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##   example: <br>\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  module_url = \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\"\n",
        "  embed = hub.Module(module_url)\n",
        "  embeddings = embed([\"A long sentence.\", \"single-word\",      \"http://example.com\"])\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "\n",
        "    print(sess.run(embeddings))\n",
        "    ```"
      ]
    },
    {
      "metadata": {
        "id": "vI8y0Nfwo7iZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## nnlm-en-dim128-with-normalization"
      ]
    },
    {
      "metadata": {
        "id": "i8DBvgKXvrS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1737
        },
        "outputId": "e57860b6-4473-4f79-823a-b98be468d92e"
      },
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/hub/\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  module_url = \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\"\n",
        "  embed = hub.Module(module_url)\n",
        "  embeddings = embed([\"A long sentence.\", \"single-word\",\n",
        "                      \"http://example.com\"])\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "\n",
        "    print(sess.run(embeddings))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1'.\n",
            "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1'.\n",
            "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/2cdbcae1a547f4fb93475d4b7d4140f8590995b7/variables/variables' with embeddings\n",
            "[[ 1.27072588e-01  1.70752838e-01 -9.90944505e-02  7.04903603e-02\n",
            "   2.26204265e-02 -8.07912350e-02  1.34882599e-01  9.98359919e-02\n",
            "  -9.38840210e-02  1.57970995e-01  1.49555340e-01 -7.23052993e-02\n",
            "   2.82968562e-02 -7.33467517e-03  7.44888186e-02 -2.56097335e-02\n",
            "   1.71663105e-01 -2.87602507e-02  5.61525524e-02  1.13487214e-01\n",
            "  -1.64960790e-02 -6.53510634e-03 -2.56301146e-02 -8.42670649e-02\n",
            "   8.53472874e-02 -5.40463366e-02  7.97923282e-02 -1.38562024e-01\n",
            "  -1.34141564e-01 -7.57983997e-02 -9.42738429e-02 -7.67866522e-02\n",
            "  -1.52945921e-01  1.80598632e-01  1.54585212e-01 -1.51075236e-02\n",
            "   3.27526703e-02  9.76694282e-03 -5.50296791e-02  6.87522218e-02\n",
            "  -4.60033529e-02 -6.41337559e-02  9.67478678e-02  2.06821620e-01\n",
            "  -3.41980383e-02  1.59218937e-01 -1.25459984e-01  1.11098640e-01\n",
            "  -8.97483621e-03  7.16845766e-02  9.47824046e-02 -1.14044234e-01\n",
            "  -2.18231454e-01 -4.69759107e-03 -2.76438929e-02  2.92292908e-02\n",
            "   1.41192973e-02  6.26731515e-02  3.51911001e-02 -1.73642084e-01\n",
            "   8.29070657e-02 -1.18464530e-01 -8.74368250e-02 -1.62412580e-02\n",
            "  -4.14458057e-03 -1.18615655e-02  9.39175263e-02 -1.17727164e-02\n",
            "   2.83051848e-01  1.87420789e-02  1.26769364e-01 -9.13429037e-02\n",
            "  -6.77580535e-02  1.13872193e-01 -6.40679523e-02 -1.89478360e-02\n",
            "  -4.26675156e-02 -1.19967490e-01 -7.73138553e-02 -6.68730959e-03\n",
            "  -9.00509208e-02 -1.30520999e-01 -8.98061469e-02 -6.32589459e-02\n",
            "  -9.09845829e-02  1.21538714e-01 -6.52545616e-02 -7.85295740e-02\n",
            "   1.02294661e-01  3.03624161e-02  3.01996730e-02 -9.32699665e-02\n",
            "  -1.10054435e-02 -2.08050162e-02  1.13857009e-01 -2.15245299e-02\n",
            "   6.13647699e-02 -1.31242042e-02 -3.28236483e-02  6.90262299e-03\n",
            "   1.03902459e-01 -3.02788205e-02  1.56071717e-02  3.76672670e-02\n",
            "   3.62532213e-02  3.31213288e-02  1.61464676e-01  3.21857892e-02\n",
            "   3.89752351e-02  9.56548825e-02 -6.67869970e-02 -3.69274579e-02\n",
            "  -8.05219859e-02  6.91312253e-02  4.07411009e-02 -2.10864067e-01\n",
            "  -5.07935062e-02 -1.45462640e-02 -1.02541111e-02 -5.36475778e-02\n",
            "   1.28856957e-01 -6.74978718e-02  5.83620146e-02 -7.19970763e-02\n",
            "  -8.85501355e-02  1.07467122e-01 -5.26525006e-02  5.70195206e-02]\n",
            " [ 1.39797762e-01  1.76146943e-02 -2.19321670e-03 -5.01641557e-02\n",
            "   8.65931250e-03 -1.54642928e-02  1.99632719e-02  4.55863215e-03\n",
            "  -1.25099957e-01  2.52421439e-01 -3.17509510e-02 -9.45225731e-02\n",
            "  -9.44786668e-02 -1.12993540e-02 -2.24387236e-02  7.62512386e-02\n",
            "  -6.99179471e-02 -5.99518083e-02 -3.97342257e-02  1.13398775e-01\n",
            "   3.38583179e-02 -9.75836664e-02  2.03888312e-01 -4.90895733e-02\n",
            "   1.46932751e-01  1.43421024e-01 -1.14350848e-01 -2.01834645e-02\n",
            "   9.81233642e-02  3.14377509e-02 -8.46532639e-03  2.13285815e-02\n",
            "  -2.09221654e-02  8.46493617e-02  5.23192324e-02 -1.57416090e-01\n",
            "   2.30358299e-02 -2.30312347e-02  9.59143639e-02  3.06421928e-02\n",
            "  -5.07018045e-02 -1.73922688e-01  1.52355462e-01 -2.39196438e-02\n",
            "  -9.08269659e-02  7.54597858e-02 -1.18609983e-02 -1.46912904e-02\n",
            "   1.52980862e-02  1.02466896e-04 -1.85660813e-02 -7.95526206e-02\n",
            "  -5.91210183e-03 -5.38629573e-03  8.39936733e-02  3.96225899e-02\n",
            "   7.02769086e-02 -4.14855666e-02 -1.77423105e-01 -3.87776196e-02\n",
            "   9.40456335e-03 -2.97141392e-02  1.17752753e-01 -1.64386898e-01\n",
            "   8.80692378e-02 -1.03511317e-02  7.22722933e-02 -1.05887815e-01\n",
            "  -4.51536886e-02 -5.57189025e-02  1.64116368e-01  1.03506930e-01\n",
            "  -1.26839839e-02  5.22539690e-02 -2.32553333e-02  5.68552464e-02\n",
            "   9.43746790e-02 -1.95228234e-01 -1.26694411e-01  5.38837984e-02\n",
            "  -3.52387317e-02 -4.82276408e-03  2.57573333e-02 -2.07264721e-02\n",
            "   4.12172899e-02  9.55006331e-02 -7.76717141e-02  5.73123386e-03\n",
            "  -6.40281662e-02  7.98024982e-02 -1.01534843e-01  4.50581051e-02\n",
            "  -1.78030925e-04 -1.32608816e-01 -2.57646833e-02  7.72607401e-02\n",
            "   2.31594145e-02 -1.75245658e-01 -9.75001305e-02  5.51053919e-02\n",
            "  -7.87429288e-02  1.57937348e-01  3.84995975e-02 -5.37735671e-02\n",
            "  -4.14606445e-02  9.66482982e-02  1.01233505e-01 -6.30216748e-02\n",
            "  -1.24483921e-01 -9.90495011e-02 -6.28274158e-02 -7.91508853e-02\n",
            "  -2.27127373e-01 -1.50987715e-01  1.46733865e-01 -1.19066767e-01\n",
            "  -6.16818778e-02 -3.62560357e-04  6.51155859e-02 -1.02088332e-01\n",
            "  -4.58937511e-02 -2.52730679e-02  1.34496652e-02  1.24088489e-01\n",
            "  -9.87231433e-02 -3.80832553e-02  1.34421334e-01 -1.19824417e-01]\n",
            " [ 1.52216060e-02  8.24953371e-04  1.99719444e-01 -1.46137387e-01\n",
            "  -1.22308068e-01  1.55805692e-01 -2.32418999e-02 -7.52224252e-02\n",
            "  -4.20164280e-02  1.49874479e-01  9.84107610e-03 -6.84494376e-02\n",
            "   8.18231553e-02 -2.81363223e-02  1.33928806e-01  5.43540902e-03\n",
            "  -8.25746953e-02  4.35561799e-02 -5.38478792e-02  3.66721563e-02\n",
            "  -9.87479985e-02 -1.73552662e-01  8.67755935e-02  2.71751191e-02\n",
            "  -2.72551924e-02 -1.21760905e-01 -2.26816162e-02 -4.55753393e-02\n",
            "  -7.81032145e-02  2.19519019e-01  5.62485456e-02 -4.14925441e-02\n",
            "   9.23696756e-02 -5.38715348e-02  1.10585578e-01  9.88290086e-03\n",
            "   1.02493148e-02  7.95307830e-02  1.77282035e-01 -1.64744675e-01\n",
            "  -1.04987651e-01 -5.18540591e-02 -5.30396104e-02 -6.86600953e-02\n",
            "   1.04234710e-01 -2.12737814e-01 -9.42418352e-03 -1.55368641e-01\n",
            "  -8.65867510e-02  3.24316621e-02 -1.44786737e-03 -1.43077501e-04\n",
            "  -8.95045996e-02 -2.60293819e-02  8.23229924e-03  1.26692593e-01\n",
            "  -1.30840510e-01 -5.90632111e-02  1.32042050e-01 -1.99757516e-01\n",
            "  -7.21374005e-02 -9.46219191e-02  1.22296609e-01 -1.77953720e-01\n",
            "   9.17489901e-02 -4.52072024e-02  1.25145391e-01 -1.68095864e-02\n",
            "  -1.37915984e-01  1.78594604e-01  1.78884529e-02  1.45819550e-02\n",
            "  -9.32844803e-02 -9.28657502e-03  4.84160194e-03 -5.09360172e-02\n",
            "  -1.55417770e-01 -1.16026811e-01  1.10570997e-01 -2.07548812e-01\n",
            "  -5.03299907e-02  1.24898115e-02 -8.26841891e-02  1.37907490e-02\n",
            "  -3.87401395e-02 -1.08496778e-01 -1.33628637e-01 -9.58182849e-03\n",
            "  -8.24758038e-02  1.37793586e-01 -1.96412113e-03  3.82586848e-03\n",
            "   1.09309312e-02 -1.50369570e-01  9.96210575e-02 -5.08368835e-02\n",
            "   9.69751924e-03 -2.83329394e-02 -1.59049034e-01 -9.43700522e-02\n",
            "  -9.63988677e-02  1.37655074e-02  1.31605327e-01 -8.06204230e-02\n",
            "   9.46079940e-02  3.53346691e-02  8.97565410e-02  1.31727224e-02\n",
            "  -9.40365866e-02  8.06342531e-03 -6.92771822e-02  1.17157549e-01\n",
            "  -1.44120455e-01 -1.26138076e-01 -1.00479638e-02 -4.77381758e-02\n",
            "   1.78717062e-01  5.12011573e-02  1.51454821e-01  2.50289198e-02\n",
            "  -2.56797373e-02  7.52567798e-02  1.58054665e-01  4.14851606e-02\n",
            "   5.66941090e-02  1.14213511e-01  1.32193893e-01 -9.23611596e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wyu3s8g_pDPD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## img. class - inception_resnet_v2"
      ]
    },
    {
      "metadata": {
        "id": "FRwDX4YmvrTD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "module = hub.Module(\"https://tfhub.dev/google/imagenet/inception_resnet_v2/classification/1\")\n",
        "height, width = hub.get_expected_image_size(module)\n",
        "images = ...  # A batch of images with shape [batch_size, height, width, 3].\n",
        "logits = module(images)  # Logits with shape [batch_size, num_classes]."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cvgZ3iSGvrTG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UbjEkmSpNAM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## IMG retraining\n",
        "https://www.tensorflow.org/hub/tutorials/image_retraining "
      ]
    },
    {
      "metadata": {
        "id": "Nj8g5jFlvrTI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KT5swfeCvrTJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pgz_eSa3vr9F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TH - text classification tutorial\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/docs/tutorials/text_classification_with_tf_hub.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/tensorflow/hub/blob/master/docs/tutorials/text_classification_with_tf_hub.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</td></table>\n",
        "<br><br><br>\n",
        "\n",
        "data:  [Large Movie Review Dataset v1.0](http://ai.stanford.edu/~amaas/data/sentiment/) \n",
        "\n",
        "The dataset consists of IMDB movie reviews labeled by positivity from 1 to 10. \n",
        "\n",
        "The task is to label the reviews as **negative** or **positive**.\n"
      ]
    },
    {
      "metadata": {
        "id": "RFbw4uozvr9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "018c2e7d-94de-472d-d625-9146c73ffab2"
      },
      "cell_type": "code",
      "source": [
        "# >>> Preparing environment\n",
        "# Install the latest Tensorflow version.\n",
        "!pip install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip install tensorflow-hub\n",
        "!pip install seaborn\n",
        "\n",
        "\n",
        "# >>>>> import libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.14.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (39.1.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xfRzIVm7vr9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f2475b74-6a05-4896-bd46-aab05dd447ed"
      },
      "cell_type": "code",
      "source": [
        "# data:  \n",
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(directory):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = []\n",
        "  data[\"sentiment\"] = []\n",
        "  for file_path in os.listdir(directory):\n",
        "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "      data[\"sentence\"].append(f.read())\n",
        "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "  \n",
        "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \"aclImdb\", \"train\"))\n",
        "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \"aclImdb\", \"test\"))\n",
        "  \n",
        "  return train_df, test_df\n",
        "\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "train_df, test_df = download_and_load_datasets()\n",
        "train_df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The episodic version of Robert Heinlein's Star...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Normally I try to avoid Sci-Fi movies as much ...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Most who go to this movie will have an idea wh...</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;br /&gt;&lt;br /&gt;An old man works as a janitor in a...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I have to say the first I watched this film wa...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment  polarity\n",
              "0  The episodic version of Robert Heinlein's Star...         3         0\n",
              "1  Normally I try to avoid Sci-Fi movies as much ...         9         1\n",
              "2  Most who go to this movie will have an idea wh...         7         1\n",
              "3  <br /><br />An old man works as a janitor in a...        10         1\n",
              "4  I have to say the first I watched this film wa...         1         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "Xt5BcCuCZ65M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "**Input functions** \n",
        "[Estimator framework](https://www.tensorflow.org/get_started/premade_estimators#overview_of_programming_with_estimators) provides [input functions](https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/pandas_input_fn) that wrap Pandas dataframes.\n",
        "\n",
        "**  Feature columns ** \n",
        "\n",
        "TF-Hub provides a [feature column](https://github.com/tensorflow/hub/blob/master/docs/api_docs/python/hub/text_embedding_column.md) that applies a module on the given text feature and passes further the outputs of the module. In this tutorial we will be using the [nnlm-en-dim128 module](https://tfhub.dev/google/nnlm-en-dim128/1). For the purpose of this tutorial, the most important facts are:\n",
        "\n",
        "* The module takes **a batch of sentences in a 1-D tensor of strings** as input.\n",
        "* The module is responsible for **preprocessing of sentences** (e.g. removal of punctuation and splitting on spaces).\n",
        "* The module works with any input (e.g. **nnlm-en-dim128** hashes words not present in vocabulary into ~20.000 buckets).\n",
        "\n",
        "**  Estimator**  For classification we can use a [DNN Classifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) (note further remarks about different modelling of the label function at the end of the tutorial)."
      ]
    },
    {
      "metadata": {
        "id": "G-a4jtbmvr9Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training input on the whole training set with no limit on training epochs.\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    train_df, train_df[\"polarity\"], num_epochs=None, shuffle=True)\n",
        "\n",
        "# Prediction on the whole training set.\n",
        "predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    train_df, train_df[\"polarity\"], shuffle=False)\n",
        "# Prediction on the test set.\n",
        "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    test_df, test_df[\"polarity\"], shuffle=False)\n",
        "\n",
        "embedded_text_feature_column = hub.text_embedding_column(\n",
        "    key=\"sentence\", \n",
        "    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
        "\n",
        "#>>> estimator \n",
        "estimator = tf.estimator.DNNClassifier(\n",
        "    hidden_units=[500, 100],\n",
        "    feature_columns=[embedded_text_feature_column],\n",
        "    n_classes=2,\n",
        "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_l1naYlLvr9U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#>>> training \n",
        "# Training for 1,000 steps means 128,000 training examples with the default\n",
        "# batch size. This is roughly equivalent to 5 epochs since the training dataset\n",
        "# contains 25,000 examples.\n",
        "estimator.train(input_fn=train_input_fn, steps=1000);\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r7ldpNNacY2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "540a89cf-0b8b-4434-9f70-1d0430b93c9a"
      },
      "cell_type": "code",
      "source": [
        "#>>>> new data \n",
        "test_df  # .columns # Index(['sentence', 'sentiment', 'polarity'], dtype='object')\n",
        "d =  { 'sentence': ['I liked the movie', \n",
        "                    'I hate the movie'], \n",
        "      'sentiment': [8, 1], \n",
        "      'polarity': [1, 0] }\n",
        "\n",
        "\n",
        "new_df = pd.DataFrame(data=d)\n",
        "# new_df\n",
        "\n",
        "predict_new_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    new_df, new_df[\"polarity\"], shuffle=False)\n",
        "\n",
        "# new_eval_result = estimator.evaluate(input_fn=predict_new_input_fn)\n",
        "new_pred_result = estimator.predict(input_fn=predict_new_input_fn)\n",
        "\n",
        "# template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "# print(template.format(iris_data.SPECIES[class_id],\n",
        "#                       100 * probability, expec))\n",
        "\n",
        "for pred_dict in zip(new_pred_result): \n",
        "  print( pred_dict )\n",
        "  print( pred_dict[0][\"probabilities\"]  )\n",
        "#   print( \"prob to be 0: {} \" .format( pred_dict[\"probabilities\"][0] ) )\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'logits': array([0.58009857], dtype=float32), 'logistic': array([0.6410901], dtype=float32), 'probabilities': array([0.3589099, 0.6410901], dtype=float32), 'class_ids': array([1]), 'classes': array([b'1'], dtype=object)},)\n",
            "[0.3589099 0.6410901]\n",
            "({'logits': array([-1.2877575], dtype=float32), 'logistic': array([0.21623263], dtype=float32), 'probabilities': array([0.78376734, 0.21623261], dtype=float32), 'class_ids': array([0]), 'classes': array([b'0'], dtype=object)},)\n",
            "[0.78376734 0.21623261]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iLGn3OCNg6Sa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8I_2mgNvr9X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f2c4a39b-1ffc-4110-c757-741287031f84"
      },
      "cell_type": "code",
      "source": [
        "#>>> Predictions\n",
        "train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
        "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
        "\n",
        "print(\"Training set accuracy: {accuracy}\".format(**train_eval_result))\n",
        "print(\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set accuracy: 0.7991600036621094\n",
            "Test set accuracy: 0.7907199859619141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A4EZbVRFaxoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "afb90d51-29c9-4e97-bd1a-6a2ec9cc0327"
      },
      "cell_type": "code",
      "source": [
        "# confusion matrix: \n",
        "def get_predictions(estimator, input_fn):\n",
        "  return [x[\"class_ids\"][0] for x in estimator.predict(input_fn=input_fn)]\n",
        "\n",
        "LABELS = [\n",
        "    \"negative\", \"positive\"\n",
        "]\n",
        "\n",
        "# Create a confusion matrix on training data.\n",
        "with tf.Graph().as_default():\n",
        "  cm = tf.confusion_matrix(train_df[\"polarity\"], \n",
        "                           get_predictions(estimator, predict_train_input_fn))\n",
        "  with tf.Session() as session:\n",
        "    cm_out = session.run(cm)\n",
        "\n",
        "# Normalize the confusion matrix so that each row sums to 1.\n",
        "cm_out = cm_out.astype(float) / cm_out.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "sns.heatmap(cm_out, annot=True, xticklabels=LABELS, yticklabels=LABELS);\n",
        "plt.xlabel(\"Predicted\");\n",
        "plt.ylabel(\"True\");"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdIAAAFYCAYAAADnS32IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3c8bb96a20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "-YxDIIr5bKvU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Further improvements\n",
        "\n",
        "1. **Regression on sentiment**: we used a classifier to assign each example into a polarity class. But we actually have another categorical feature at our disposal - sentiment. Here classes actually represent a scale and the underlying value (positive/negative) could be well mapped into a continuous range. We could make use of this property by computing a regression ([DNN Regressor](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNRegressor)) instead of a classification ([DNN Classifier](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier)).\n",
        "2. **Larger module**: for the purposes of this tutorial we used a small module to restrict the memory use. There are modules with larger vocabularies and larger embedding space that could give additional accuracy points.\n",
        "3. **Parameter tuning**: we can improve the accuracy by tuning the meta-parameters like the learning rate or the number of steps, especially if we use a different module. A validation set is very important if we want to get any reasonable results, because it is very easy to set-up a model that learns to predict the training data without generalizing well to the test set.\n",
        "4. **More complex model**: we used a module that computes a sentence embedding by embedding each individual word and then combining them with average. One could also use a sequential module (e.g. [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/2) module) to better capture the nature of sentences. Or an ensemble of two or more TF-Hub modules.\n",
        "5. **Regularization**: to prevent overfitting, we could try to use an optimizer that does some sort of regularization, for example [Proximal Adagrad Optimizer](https://www.tensorflow.org/api_docs/python/tf/train/ProximalAdagradOptimizer)."
      ]
    },
    {
      "metadata": {
        "id": "4mzXTYXobQT7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Advanced: Transfer learning analysis\n",
        "\n",
        "Transfer learning makes it possible to **save training resources** and to achieve good model generalization even when **training on a small dataset**. In this part, we will demonstrate this by training with two different TF-Hub modules:\n",
        "\n",
        "* **[nnlm-en-dim128](https://tfhub.dev/google/nnlm-en-dim128/1)** - pretrained text embedding module,\n",
        "* **[random-nnlm-en-dim128](https://tfhub.dev/google/random-nnlm-en-dim128/1)** - text embedding module that has same vocabulary and network as **nnlm-en-dim128**, but the weights were just randomly initialized and never trained on real data.\n",
        "\n",
        "And by training in two modes: \n",
        "\n",
        "* training **only the classifier** (i.e. freezing the module), and \n",
        "* training the **classifier together with the module**.\n",
        "\n",
        "Let's run a couple of trainings and evaluations to see how using a various modules can affect the accuracy."
      ]
    },
    {
      "metadata": {
        "id": "QxCnCCNiaxq6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_with_module(hub_module, train_module=False):\n",
        "  embedded_text_feature_column = hub.text_embedding_column(\n",
        "      key=\"sentence\", module_spec=hub_module, trainable=train_module)\n",
        "\n",
        "  estimator = tf.estimator.DNNClassifier(\n",
        "      hidden_units=[500, 100],\n",
        "      feature_columns=[embedded_text_feature_column],\n",
        "      n_classes=2,\n",
        "      optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
        "\n",
        "  estimator.train(input_fn=train_input_fn, steps=1000)\n",
        "\n",
        "  train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
        "  test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
        "\n",
        "  training_set_accuracy = train_eval_result[\"accuracy\"]\n",
        "  test_set_accuracy = test_eval_result[\"accuracy\"]\n",
        "\n",
        "  return {\n",
        "      \"Training accuracy\": training_set_accuracy,\n",
        "      \"Test accuracy\": test_set_accuracy\n",
        "  }\n",
        "\n",
        "\n",
        "results = {}\n",
        "results[\"nnlm-en-dim128\"] = train_and_evaluate_with_module(\n",
        "    \"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
        "results[\"nnlm-en-dim128-with-module-training\"] = train_and_evaluate_with_module(\n",
        "    \"https://tfhub.dev/google/nnlm-en-dim128/1\", True)\n",
        "results[\"random-nnlm-en-dim128\"] = train_and_evaluate_with_module(\n",
        "    \"https://tfhub.dev/google/random-nnlm-en-dim128/1\")\n",
        "results[\"random-nnlm-en-dim128-with-module-training\"] = train_and_evaluate_with_module(\n",
        "    \"https://tfhub.dev/google/random-nnlm-en-dim128/1\", True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aJyZn5CbaxtZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2234f1af-4771-4b0d-ff43-3ccaf7c2a68a"
      },
      "cell_type": "code",
      "source": [
        "pd.DataFrame.from_dict(results, orient=\"index\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training accuracy</th>\n",
              "      <th>Test accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>nnlm-en-dim128</th>\n",
              "      <td>0.80280</td>\n",
              "      <td>0.79460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nnlm-en-dim128-with-module-training</th>\n",
              "      <td>0.95128</td>\n",
              "      <td>0.87140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>random-nnlm-en-dim128</th>\n",
              "      <td>0.71920</td>\n",
              "      <td>0.67704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>random-nnlm-en-dim128-with-module-training</th>\n",
              "      <td>0.76648</td>\n",
              "      <td>0.71956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Training accuracy  Test accuracy\n",
              "nnlm-en-dim128                                        0.80280        0.79460\n",
              "nnlm-en-dim128-with-module-training                   0.95128        0.87140\n",
              "random-nnlm-en-dim128                                 0.71920        0.67704\n",
              "random-nnlm-en-dim128-with-module-training            0.76648        0.71956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "BCs_DBcCbZft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc12eb33-f13d-4057-9b6f-43a73e0967f7"
      },
      "cell_type": "code",
      "source": [
        "estimator.evaluate(input_fn=predict_test_input_fn)[\"accuracy_baseline\"]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "KWKp1QtqwzBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8a907530-ad84-4618-e6c2-707785b0baca"
      },
      "cell_type": "code",
      "source": [
        "estimator.evaluate(input_fn=predict_test_input_fn)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.79072,\n",
              " 'accuracy_baseline': 0.5,\n",
              " 'auc': 0.8763104,\n",
              " 'auc_precision_recall': 0.8787724,\n",
              " 'average_loss': 0.44577765,\n",
              " 'global_step': 1000,\n",
              " 'label/mean': 0.5,\n",
              " 'loss': 56.859394,\n",
              " 'precision': 0.8274464,\n",
              " 'prediction/mean': 0.46147138,\n",
              " 'recall': 0.73464}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "KPBn18vpbbab",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Assigning the most represented class will give us accuracy of **50%**. There are a couple of things to notice here:\n",
        "\n",
        "1. Maybe surprisingly, **a model can still be learned on top of fixed, random embeddings**. The reason is that even if every word in the dictionary is mapped to a random vector, the estimator can separate the space purely using its fully connected layers.\n",
        "2. Allowing training of the module with **random embeddings** increases both training and test accuracy as oposed to training just the classifier.\n",
        "3. Training of the module with **pre-trained embeddings** also increases both accuracies. Note however the overfitting on the training set. Training a pre-trained module can be dangerous even with regularization in the sense that the embedding weights no longer represent the language model trained on diverse data, instead they converge to the ideal representation of the new dataset."
      ]
    },
    {
      "metadata": {
        "id": "DJQ0kaxovuF_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# next 4\n"
      ]
    },
    {
      "metadata": {
        "id": "4TVdMVz-vuGA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ... "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z98f05I-vuGG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V0UTmECxvuGJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OuH72lqEvuGL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yWJg443svuGN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}