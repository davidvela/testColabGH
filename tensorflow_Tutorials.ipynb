{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_Tutorials.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "LteTUhcRrwka",
        "vI8y0Nfwo7iZ",
        "Pgz_eSa3vr9F",
        "DJQ0kaxovuF_"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/davidvela/testColabGH/blob/master/tensorflow_Tutorials.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "lHo_KGPfrkOi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorflow Tutorials - Intro"
      ]
    },
    {
      "metadata": {
        "id": "AQYbGjDxtsxf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "my noes: \n",
        "seems like tensorflow examples are getting more and more closed to keros... <br> \n",
        "the code seems more simple and with less lines. <br> \n",
        "the question is if it will affect performance and if keras has all the objects and all the customization from the old tensorflow libraries... (tf.layers ... )"
      ]
    },
    {
      "metadata": {
        "id": "MhoQ0WE77laV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "metadata": {
        "id": "_ckMIh7O7s6D",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vasWnqRgy1H4",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jYysdyb-CaWM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST dataset\n",
        "Train your first neural network: basic classification\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "S5Uhzt6vVIB2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/basic_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/models/blob/master/samples/core/tutorials/keras/basic_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/samples/core/tutorials/keras/basic_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "FbVhjPpzn6BM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This guide uses [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow."
      ]
    },
    {
      "metadata": {
        "id": "DLdCchMdCaWQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This guide uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Fashion MNIST is intended as a drop-in replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset—often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc) in an identical format to the articles of clothing we'll use here.\n",
        "\n",
        "This guide uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code. \n",
        "\n",
        "We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow, just import and load the data:"
      ]
    },
    {
      "metadata": {
        "id": "dzLKpmZICaWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8550b9d7-a37c-4465-af68-f4e39833391c"
      },
      "cell_type": "code",
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7MqDQO0KCaWS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "#      0             1          2          3       4         5        6       7         8       9\n",
        "# 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Brm0b_KACaWX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Explore the data\n",
        "\n",
        "Let's explore the format of the dataset before training the model. The following shows there are 60,000 images in the training set, with each image represented as 28 x 28 pixels:"
      ]
    },
    {
      "metadata": {
        "id": "zW5k_xz1CaWX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train_images.shape) \n",
        "print(len(train_labels))\n",
        "print(train_labels)\n",
        "print(test_images.shape)\n",
        "print(len(test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ES6uQoLKCaWr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess the data\n",
        "\n",
        "The data must be preprocessed before training the network. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255:"
      ]
    },
    {
      "metadata": {
        "id": "m4VEw8Ud9Quh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.gca().grid(False)\n",
        "# scale values from 0 to 1. \n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ee638AlnCaWz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Display the first 25 images from the *training set* and display the class name below each image. Verify that the data is in the correct format and we're ready to build and train the network."
      ]
    },
    {
      "metadata": {
        "id": "oZTImqg_CaW1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid('off')\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "59veuiEZCaW4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "\n",
        "Building the neural network requires configuring the layers of the model, then compiling the model."
      ]
    },
    {
      "metadata": {
        "id": "9ODch-OFCaW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lhan11blCaW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train the model: \n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the model: \n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n",
        "#  This model reaches an accuracy of about 0.88 (or 88%) on the training data.\n",
        "\n",
        "# Testing\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# examples: \n",
        "print(predictions[0])\n",
        "print(np.argmax(predictions[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sd7Pgsu6CaXP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xsoS7CPDCaXH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make predictions\n",
        "\n",
        "With the model trained, we can use it to make predictions about some images."
      ]
    },
    {
      "metadata": {
        "id": "kgdvGD52CaXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's plot several images with their predictions. Correct prediction labels are green and incorrect prediction labels are red."
      ]
    },
    {
      "metadata": {
        "id": "YGBDAiziCaXR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot the first 25 test images, their predicted label, and the true label\n",
        "# Color correct predictions in green, incorrect predictions in red\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid('off')\n",
        "    plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
        "    predicted_label = np.argmax(predictions[i])\n",
        "    true_label = test_labels[i]\n",
        "    if predicted_label == true_label:\n",
        "      color = 'green'\n",
        "    else:\n",
        "      color = 'red'\n",
        "    plt.xlabel(\"{} ({})\".format(class_names[predicted_label], \n",
        "                                  class_names[true_label]),\n",
        "                                  color=color)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R32zteKHCaXT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, use the trained model to make a prediction about a single image. "
      ]
    },
    {
      "metadata": {
        "id": "yRJ7JU7JCaXT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Grab an image from the test dataset\n",
        "img = test_images[0]\n",
        "print(img.shape)\n",
        "# Add the image to a batch where it's the only member.\n",
        "img = (np.expand_dims(img,0))\n",
        "print(img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQ5wLTkcCaXY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now predict the image:"
      ]
    },
    {
      "metadata": {
        "id": "o_rzNSdrCaXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(img)\n",
        "print(predictions)\n",
        "prediction = predictions[0]\n",
        "np.argmax(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LteTUhcRrwka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The Boston Housing Prices dataset"
      ]
    },
    {
      "metadata": {
        "id": "EOH9n3I3ryDe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ... "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cg9j7BvCry87",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NbrmdxBjvW_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CMY8myeXvXCD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9FOgqpK7vXFF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LWK8JpoovtgN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Machine Translation with Attention\n",
        "   <table class=\"tfo-notebook-buttons\" align=\"left\"><td>\n",
        "      <a target=\"_blank\"  href=\"https://colab.sandbox.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb\">\n",
        "      <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "        <span>Run in Google Colab</span></a>  \n",
        "        </td><td>\n",
        "        <a target=\"_blank\"  href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /><span>View source on GitHub</span></a></td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "SQWL6xObvtgO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ... "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9Zxli-2vtgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# Import TensorFlow >= 1.9 and enable eager execution\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m8OWSnw3vtgS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nf-X51i-vtgV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkChf5oyvtga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "403mugX_vrS-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorflowHub\n",
        "  https://www.tensorflow.org/hub/ <br>\n",
        "  modules: https://www.tensorflow.org/hub/modules/google/imagenet/inception_resnet_v2/classification/1\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "cajYirVJ0gcK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##   example: <br>\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  module_url = \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\"\n",
        "  embed = hub.Module(module_url)\n",
        "  embeddings = embed([\"A long sentence.\", \"single-word\",      \"http://example.com\"])\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "\n",
        "    print(sess.run(embeddings))\n",
        "    ```"
      ]
    },
    {
      "metadata": {
        "id": "vI8y0Nfwo7iZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## nnlm-en-dim128-with-normalization"
      ]
    },
    {
      "metadata": {
        "id": "i8DBvgKXvrS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1737
        },
        "outputId": "e57860b6-4473-4f79-823a-b98be468d92e"
      },
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/hub/\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  module_url = \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\"\n",
        "  embed = hub.Module(module_url)\n",
        "  embeddings = embed([\"A long sentence.\", \"single-word\",\n",
        "                      \"http://example.com\"])\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "\n",
        "    print(sess.run(embeddings))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1'.\n",
            "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1'.\n",
            "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/2cdbcae1a547f4fb93475d4b7d4140f8590995b7/variables/variables' with embeddings\n",
            "[[ 1.27072588e-01  1.70752838e-01 -9.90944505e-02  7.04903603e-02\n",
            "   2.26204265e-02 -8.07912350e-02  1.34882599e-01  9.98359919e-02\n",
            "  -9.38840210e-02  1.57970995e-01  1.49555340e-01 -7.23052993e-02\n",
            "   2.82968562e-02 -7.33467517e-03  7.44888186e-02 -2.56097335e-02\n",
            "   1.71663105e-01 -2.87602507e-02  5.61525524e-02  1.13487214e-01\n",
            "  -1.64960790e-02 -6.53510634e-03 -2.56301146e-02 -8.42670649e-02\n",
            "   8.53472874e-02 -5.40463366e-02  7.97923282e-02 -1.38562024e-01\n",
            "  -1.34141564e-01 -7.57983997e-02 -9.42738429e-02 -7.67866522e-02\n",
            "  -1.52945921e-01  1.80598632e-01  1.54585212e-01 -1.51075236e-02\n",
            "   3.27526703e-02  9.76694282e-03 -5.50296791e-02  6.87522218e-02\n",
            "  -4.60033529e-02 -6.41337559e-02  9.67478678e-02  2.06821620e-01\n",
            "  -3.41980383e-02  1.59218937e-01 -1.25459984e-01  1.11098640e-01\n",
            "  -8.97483621e-03  7.16845766e-02  9.47824046e-02 -1.14044234e-01\n",
            "  -2.18231454e-01 -4.69759107e-03 -2.76438929e-02  2.92292908e-02\n",
            "   1.41192973e-02  6.26731515e-02  3.51911001e-02 -1.73642084e-01\n",
            "   8.29070657e-02 -1.18464530e-01 -8.74368250e-02 -1.62412580e-02\n",
            "  -4.14458057e-03 -1.18615655e-02  9.39175263e-02 -1.17727164e-02\n",
            "   2.83051848e-01  1.87420789e-02  1.26769364e-01 -9.13429037e-02\n",
            "  -6.77580535e-02  1.13872193e-01 -6.40679523e-02 -1.89478360e-02\n",
            "  -4.26675156e-02 -1.19967490e-01 -7.73138553e-02 -6.68730959e-03\n",
            "  -9.00509208e-02 -1.30520999e-01 -8.98061469e-02 -6.32589459e-02\n",
            "  -9.09845829e-02  1.21538714e-01 -6.52545616e-02 -7.85295740e-02\n",
            "   1.02294661e-01  3.03624161e-02  3.01996730e-02 -9.32699665e-02\n",
            "  -1.10054435e-02 -2.08050162e-02  1.13857009e-01 -2.15245299e-02\n",
            "   6.13647699e-02 -1.31242042e-02 -3.28236483e-02  6.90262299e-03\n",
            "   1.03902459e-01 -3.02788205e-02  1.56071717e-02  3.76672670e-02\n",
            "   3.62532213e-02  3.31213288e-02  1.61464676e-01  3.21857892e-02\n",
            "   3.89752351e-02  9.56548825e-02 -6.67869970e-02 -3.69274579e-02\n",
            "  -8.05219859e-02  6.91312253e-02  4.07411009e-02 -2.10864067e-01\n",
            "  -5.07935062e-02 -1.45462640e-02 -1.02541111e-02 -5.36475778e-02\n",
            "   1.28856957e-01 -6.74978718e-02  5.83620146e-02 -7.19970763e-02\n",
            "  -8.85501355e-02  1.07467122e-01 -5.26525006e-02  5.70195206e-02]\n",
            " [ 1.39797762e-01  1.76146943e-02 -2.19321670e-03 -5.01641557e-02\n",
            "   8.65931250e-03 -1.54642928e-02  1.99632719e-02  4.55863215e-03\n",
            "  -1.25099957e-01  2.52421439e-01 -3.17509510e-02 -9.45225731e-02\n",
            "  -9.44786668e-02 -1.12993540e-02 -2.24387236e-02  7.62512386e-02\n",
            "  -6.99179471e-02 -5.99518083e-02 -3.97342257e-02  1.13398775e-01\n",
            "   3.38583179e-02 -9.75836664e-02  2.03888312e-01 -4.90895733e-02\n",
            "   1.46932751e-01  1.43421024e-01 -1.14350848e-01 -2.01834645e-02\n",
            "   9.81233642e-02  3.14377509e-02 -8.46532639e-03  2.13285815e-02\n",
            "  -2.09221654e-02  8.46493617e-02  5.23192324e-02 -1.57416090e-01\n",
            "   2.30358299e-02 -2.30312347e-02  9.59143639e-02  3.06421928e-02\n",
            "  -5.07018045e-02 -1.73922688e-01  1.52355462e-01 -2.39196438e-02\n",
            "  -9.08269659e-02  7.54597858e-02 -1.18609983e-02 -1.46912904e-02\n",
            "   1.52980862e-02  1.02466896e-04 -1.85660813e-02 -7.95526206e-02\n",
            "  -5.91210183e-03 -5.38629573e-03  8.39936733e-02  3.96225899e-02\n",
            "   7.02769086e-02 -4.14855666e-02 -1.77423105e-01 -3.87776196e-02\n",
            "   9.40456335e-03 -2.97141392e-02  1.17752753e-01 -1.64386898e-01\n",
            "   8.80692378e-02 -1.03511317e-02  7.22722933e-02 -1.05887815e-01\n",
            "  -4.51536886e-02 -5.57189025e-02  1.64116368e-01  1.03506930e-01\n",
            "  -1.26839839e-02  5.22539690e-02 -2.32553333e-02  5.68552464e-02\n",
            "   9.43746790e-02 -1.95228234e-01 -1.26694411e-01  5.38837984e-02\n",
            "  -3.52387317e-02 -4.82276408e-03  2.57573333e-02 -2.07264721e-02\n",
            "   4.12172899e-02  9.55006331e-02 -7.76717141e-02  5.73123386e-03\n",
            "  -6.40281662e-02  7.98024982e-02 -1.01534843e-01  4.50581051e-02\n",
            "  -1.78030925e-04 -1.32608816e-01 -2.57646833e-02  7.72607401e-02\n",
            "   2.31594145e-02 -1.75245658e-01 -9.75001305e-02  5.51053919e-02\n",
            "  -7.87429288e-02  1.57937348e-01  3.84995975e-02 -5.37735671e-02\n",
            "  -4.14606445e-02  9.66482982e-02  1.01233505e-01 -6.30216748e-02\n",
            "  -1.24483921e-01 -9.90495011e-02 -6.28274158e-02 -7.91508853e-02\n",
            "  -2.27127373e-01 -1.50987715e-01  1.46733865e-01 -1.19066767e-01\n",
            "  -6.16818778e-02 -3.62560357e-04  6.51155859e-02 -1.02088332e-01\n",
            "  -4.58937511e-02 -2.52730679e-02  1.34496652e-02  1.24088489e-01\n",
            "  -9.87231433e-02 -3.80832553e-02  1.34421334e-01 -1.19824417e-01]\n",
            " [ 1.52216060e-02  8.24953371e-04  1.99719444e-01 -1.46137387e-01\n",
            "  -1.22308068e-01  1.55805692e-01 -2.32418999e-02 -7.52224252e-02\n",
            "  -4.20164280e-02  1.49874479e-01  9.84107610e-03 -6.84494376e-02\n",
            "   8.18231553e-02 -2.81363223e-02  1.33928806e-01  5.43540902e-03\n",
            "  -8.25746953e-02  4.35561799e-02 -5.38478792e-02  3.66721563e-02\n",
            "  -9.87479985e-02 -1.73552662e-01  8.67755935e-02  2.71751191e-02\n",
            "  -2.72551924e-02 -1.21760905e-01 -2.26816162e-02 -4.55753393e-02\n",
            "  -7.81032145e-02  2.19519019e-01  5.62485456e-02 -4.14925441e-02\n",
            "   9.23696756e-02 -5.38715348e-02  1.10585578e-01  9.88290086e-03\n",
            "   1.02493148e-02  7.95307830e-02  1.77282035e-01 -1.64744675e-01\n",
            "  -1.04987651e-01 -5.18540591e-02 -5.30396104e-02 -6.86600953e-02\n",
            "   1.04234710e-01 -2.12737814e-01 -9.42418352e-03 -1.55368641e-01\n",
            "  -8.65867510e-02  3.24316621e-02 -1.44786737e-03 -1.43077501e-04\n",
            "  -8.95045996e-02 -2.60293819e-02  8.23229924e-03  1.26692593e-01\n",
            "  -1.30840510e-01 -5.90632111e-02  1.32042050e-01 -1.99757516e-01\n",
            "  -7.21374005e-02 -9.46219191e-02  1.22296609e-01 -1.77953720e-01\n",
            "   9.17489901e-02 -4.52072024e-02  1.25145391e-01 -1.68095864e-02\n",
            "  -1.37915984e-01  1.78594604e-01  1.78884529e-02  1.45819550e-02\n",
            "  -9.32844803e-02 -9.28657502e-03  4.84160194e-03 -5.09360172e-02\n",
            "  -1.55417770e-01 -1.16026811e-01  1.10570997e-01 -2.07548812e-01\n",
            "  -5.03299907e-02  1.24898115e-02 -8.26841891e-02  1.37907490e-02\n",
            "  -3.87401395e-02 -1.08496778e-01 -1.33628637e-01 -9.58182849e-03\n",
            "  -8.24758038e-02  1.37793586e-01 -1.96412113e-03  3.82586848e-03\n",
            "   1.09309312e-02 -1.50369570e-01  9.96210575e-02 -5.08368835e-02\n",
            "   9.69751924e-03 -2.83329394e-02 -1.59049034e-01 -9.43700522e-02\n",
            "  -9.63988677e-02  1.37655074e-02  1.31605327e-01 -8.06204230e-02\n",
            "   9.46079940e-02  3.53346691e-02  8.97565410e-02  1.31727224e-02\n",
            "  -9.40365866e-02  8.06342531e-03 -6.92771822e-02  1.17157549e-01\n",
            "  -1.44120455e-01 -1.26138076e-01 -1.00479638e-02 -4.77381758e-02\n",
            "   1.78717062e-01  5.12011573e-02  1.51454821e-01  2.50289198e-02\n",
            "  -2.56797373e-02  7.52567798e-02  1.58054665e-01  4.14851606e-02\n",
            "   5.66941090e-02  1.14213511e-01  1.32193893e-01 -9.23611596e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wyu3s8g_pDPD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## img. class - inception_resnet_v2"
      ]
    },
    {
      "metadata": {
        "id": "FRwDX4YmvrTD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "module = hub.Module(\"https://tfhub.dev/google/imagenet/inception_resnet_v2/classification/1\")\n",
        "height, width = hub.get_expected_image_size(module)\n",
        "images = ...  # A batch of images with shape [batch_size, height, width, 3].\n",
        "logits = module(images)  # Logits with shape [batch_size, num_classes]."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cvgZ3iSGvrTG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UbjEkmSpNAM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## IMG retraining\n",
        "https://www.tensorflow.org/hub/tutorials/image_retraining "
      ]
    },
    {
      "metadata": {
        "id": "Nj8g5jFlvrTI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KT5swfeCvrTJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pgz_eSa3vr9F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# next 2"
      ]
    },
    {
      "metadata": {
        "id": "RFbw4uozvr9J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ... "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xfRzIVm7vr9L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G-a4jtbmvr9Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_l1naYlLvr9U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8I_2mgNvr9X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DJQ0kaxovuF_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# next 4\n"
      ]
    },
    {
      "metadata": {
        "id": "4TVdMVz-vuGA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ... "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z98f05I-vuGG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V0UTmECxvuGJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OuH72lqEvuGL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yWJg443svuGN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}